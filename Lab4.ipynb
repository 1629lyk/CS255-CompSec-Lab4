{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "823ecc0e",
   "metadata": {},
   "source": [
    "## Lab 4 Adversarial Learning\n",
    "### Name: Lakhan Kumar Sunilkumar\n",
    "### SID: 862481700\n",
    "### Email: lsuni001@ucr.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f1cce3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "CUDA device 0: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Imports, CUDA check, and safe globals for ResNet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.serialization import add_safe_globals\n",
    "from torchvision.models.resnet import ResNet, BasicBlock, Bottleneck\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "# Register all classes used inside torchvision ResNet as safe\n",
    "add_safe_globals([\n",
    "    ResNet,\n",
    "    BasicBlock,\n",
    "    Bottleneck,\n",
    "    nn.Conv2d,\n",
    "    nn.BatchNorm2d,\n",
    "    nn.Linear,\n",
    "    nn.ReLU,\n",
    "    nn.MaxPool2d,\n",
    "    nn.AdaptiveAvgPool2d,\n",
    "    nn.Sequential,\n",
    "    nn.Dropout,\n",
    "])\n",
    "\n",
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    props = torch.cuda.get_device_properties(i)\n",
    "    print(f\"CUDA device {i}: {props.name}\")\n",
    "\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07ba3d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded with weights_only=True and set to eval() on cuda:0\n",
      "Model type: <class 'torchvision.models.resnet.ResNet'>\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ResNet model safely \n",
    "\n",
    "# Path to model file\n",
    "RESNET_MODEL_FILE = \"./resnet.model\"\n",
    "\n",
    "# Load the model with safe globals\n",
    "model = torch.load(\n",
    "    RESNET_MODEL_FILE,\n",
    "    map_location=device,\n",
    "    weights_only=True\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded with weights_only=True and set to eval() on\", device)\n",
    "print(\"Model type:\", type(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49c67cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded testset object type: <class 'list'>\n",
      "Interpreting testset as list of (img, label) pairs\n",
      "Derived stacked input_imgs shape: torch.Size([100, 3, 32, 32])\n",
      "Derived stacked labels shape: torch.Size([100])\n",
      "Number of samples: 100\n",
      "DataLoader ready; number of batches: 13\n"
     ]
    }
   ],
   "source": [
    "TESTSET_FILE = \"./testset.pt\"\n",
    "\n",
    "testset_obj = torch.load(TESTSET_FILE, map_location=\"cpu\", weights_only=True)\n",
    "print(\"Loaded testset object type:\", type(testset_obj))\n",
    "\n",
    "# Case 1: (input_imgs, labels) tuple of tensors\n",
    "if (\n",
    "    isinstance(testset_obj, (tuple, list))\n",
    "    and len(testset_obj) == 2\n",
    "    and torch.is_tensor(testset_obj[0])\n",
    "    and torch.is_tensor(testset_obj[1])\n",
    "):\n",
    "    input_imgs, labels = testset_obj\n",
    "    print(\"Interpreting testset as (input_imgs, labels) tensors\")\n",
    "    print(\"input_imgs shape:\", input_imgs.shape)\n",
    "    print(\"labels shape:\", labels.shape)\n",
    "    dataset = TensorDataset(input_imgs, labels)\n",
    "\n",
    "# Case 2: list of (img, label) pairs, labels as ints\n",
    "elif (\n",
    "    isinstance(testset_obj, list)\n",
    "    and len(testset_obj) > 0\n",
    "    and isinstance(testset_obj[0], tuple)\n",
    "    and len(testset_obj[0]) == 2\n",
    "):\n",
    "    print(\"Interpreting testset as list of (img, label) pairs\")\n",
    "    dataset = testset_obj\n",
    "    input_imgs = torch.stack([x for x, _ in dataset], dim=0)\n",
    "    labels = torch.tensor([int(y) for _, y in dataset], dtype=torch.long)\n",
    "    print(\"Derived stacked input_imgs shape:\", input_imgs.shape)\n",
    "    print(\"Derived stacked labels shape:\", labels.shape)\n",
    "else:\n",
    "    raise RuntimeError(\"Unexpected format of testset.pt\")\n",
    "\n",
    "NUM_SAMPLES = input_imgs.shape[0]\n",
    "print(\"Number of samples:\", NUM_SAMPLES)\n",
    "\n",
    "BATCH_SIZE = 8 \n",
    "\n",
    "testloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "print(\"DataLoader ready; number of batches:\", len(testloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f4b7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample value range: [-1.000, 1.000]\n",
      "Detected normalized range ~[-1, 1]; using clamp [-1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Peek at a batch to infer value range\n",
    "sample_imgs, _ = next(iter(testloader))\n",
    "vmin = sample_imgs.min().item()\n",
    "vmax = sample_imgs.max().item()\n",
    "print(f\"Sample value range: [{vmin:.3f}, {vmax:.3f}]\")\n",
    "\n",
    "if vmin >= -1.05 and vmax <= 1.05:\n",
    "    CLAMP_MIN, CLAMP_MAX = -1.0, 1.0\n",
    "    print(\"Detected normalized range ~[-1, 1]; using clamp [-1, 1]\")\n",
    "elif vmin >= -0.01 and vmax <= 1.01:\n",
    "    CLAMP_MIN, CLAMP_MAX = 0.0, 1.0\n",
    "    print(\"Detected range ~[0, 1]; using clamp [0, 1]\")\n",
    "else:\n",
    "    # fallback: use observed min/max with small buffer\n",
    "    CLAMP_MIN, CLAMP_MAX = vmin - 1e-3, vmax + 1e-3\n",
    "    print(f\"Using clamp [{CLAMP_MIN:.3f}, {CLAMP_MAX:.3f}] (fallback)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f910a43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (clean)...: 100%|██████████| 13/13 [00:01<00:00, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Top-1 accuracy: 0.8200\n",
      "Original Top-5 accuracy: 0.9700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute Top-1 / Top-5 accuracy\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_topk_accuracies(model, loader, device, ks=(1, 5)):\n",
    "    model.eval()\n",
    "    correct_k = {k: 0 for k in ks}\n",
    "    total = 0\n",
    "\n",
    "    for imgs, labels in tqdm.tqdm(loader, desc=\"Evaluating (clean)...\"):\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        logits = model(imgs) # (N, 1000)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "\n",
    "        for k in ks:\n",
    "            topk_idx = probs.topk(k, dim=1).indices # (N, k)\n",
    "            match = topk_idx.eq(labels.view(-1, 1)).any(dim=1)\n",
    "            correct_k[k] += match.sum().item()\n",
    "\n",
    "    topk_acc = {k: correct_k[k] / total for k in ks}\n",
    "    return topk_acc\n",
    "\n",
    "# Baseline accuracy on original test images\n",
    "\n",
    "orig_topk = compute_topk_accuracies(model, testloader, device, ks=(1, 5))\n",
    "print(f\"Original Top-1 accuracy: {orig_topk[1]:.4f}\")\n",
    "print(f\"Original Top-5 accuracy: {orig_topk[5]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "411819ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(model, input_imgs, labels, epsilon):\n",
    "    \"\"\"\n",
    "    Standard untargeted FGSM:\n",
    "      x_adv = clamp(x + eps * sign(grad_x L(model(x), y)), [CLAMP_MIN, CLAMP_MAX])\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    input_imgs = input_imgs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    input_imgs.requires_grad = True\n",
    "\n",
    "    preds = model(input_imgs)\n",
    "    loss  = nn.CrossEntropyLoss()(preds, labels)\n",
    "\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    grad = input_imgs.grad\n",
    "\n",
    "    adv = input_imgs + epsilon * torch.sign(grad)\n",
    "    adv = torch.clamp(adv, CLAMP_MIN, CLAMP_MAX)\n",
    "\n",
    "    return adv.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddcb57fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack(model, input_imgs, labels, epsilon, alpha, num_iter):\n",
    "    \"\"\"\n",
    "    L_inf PGD with projection onto epsilon-ball around original x.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    input_imgs = input_imgs.to(device)\n",
    "    labels     = labels.to(device)\n",
    "\n",
    "    # Start exactly from original images (no random start to keep eps tight)\n",
    "    x = input_imgs.clone().detach()\n",
    "    x.requires_grad = True\n",
    "\n",
    "    for _ in tqdm.tqdm(range(num_iter), desc=\"PGD iters\", leave=False):\n",
    "        preds = model(x)\n",
    "        loss  = nn.CrossEntropyLoss()(preds, labels)\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        grad = x.grad\n",
    "\n",
    "        # Gradient ascent on loss\n",
    "        x = x + alpha * torch.sign(grad)\n",
    "\n",
    "        # Project back to L_inf ball\n",
    "        x = torch.max(torch.min(x, input_imgs + epsilon), input_imgs - epsilon)\n",
    "\n",
    "        # Clamp to valid input range\n",
    "        x = torch.clamp(x, CLAMP_MIN, CLAMP_MAX)\n",
    "\n",
    "        x = x.detach()\n",
    "        x.requires_grad = True\n",
    "\n",
    "    return x.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2793bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adv_dataset_fgsm(model, loader, epsilon):\n",
    "    adv_imgs = []\n",
    "    adv_labels = []\n",
    "\n",
    "    for imgs, lbls in tqdm.tqdm(loader, desc=f\"FGSM eps={epsilon:.4f}\"):\n",
    "        adv_batch = fgsm_attack(model, imgs, lbls, epsilon=epsilon)\n",
    "        for img_adv, lbl in zip(adv_batch, lbls):\n",
    "            adv_imgs.append(img_adv.cpu())\n",
    "            adv_labels.append(int(lbl))\n",
    "\n",
    "    return adv_imgs, torch.tensor(adv_labels, dtype=torch.long)\n",
    "\n",
    "def build_adv_dataset_pgd(model, loader, epsilon, alpha, num_iter):\n",
    "    adv_imgs = []\n",
    "    adv_labels = []\n",
    "\n",
    "    for imgs, lbls in tqdm.tqdm(loader, desc=f\"PGD eps={epsilon:.4f}, iters={num_iter}\"):\n",
    "        adv_batch = pgd_attack(model, imgs, lbls, epsilon=epsilon, alpha=alpha, num_iter=num_iter)\n",
    "        for img_adv, lbl in zip(adv_batch, lbls):\n",
    "            adv_imgs.append(img_adv.cpu())\n",
    "            adv_labels.append(int(lbl))\n",
    "\n",
    "    return adv_imgs, torch.tensor(adv_labels, dtype=torch.long)\n",
    "\n",
    "def compute_adv_topk(model, adv_imgs, adv_labels, batch_size=8):\n",
    "    adv_dataset = list(zip(adv_imgs, adv_labels))\n",
    "    adv_loader = DataLoader(adv_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    return compute_topk_accuracies(model, adv_loader, device, ks=(1,5))\n",
    "\n",
    "def compute_empirical_eps(orig_imgs, adv_imgs):\n",
    "    orig = orig_imgs\n",
    "    adv = torch.stack(adv_imgs, dim=0)\n",
    "    assert orig.shape == adv.shape\n",
    "    diff = (adv - orig).abs()\n",
    "    return diff.mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28835065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_fgsm_score(tp1_diff, tp5_diff, eps_empirical):\n",
    "    \n",
    "    tp1_score = 0.33 + 33.0 * tp1_diff\n",
    "    tp5_score = 66.0 * tp5_diff\n",
    "    fgsm_score = max(tp1_score, tp5_score)\n",
    "    \n",
    "    fgsm_score = max(0.0, min(fgsm_score, 10.0))\n",
    "    return fgsm_score, tp1_score, tp5_score\n",
    "\n",
    "def estimate_pgd_score(tp1_diff, tp5_diff, eps_empirical):\n",
    "    \n",
    "    tp1_score = 26.0 * tp1_diff\n",
    "    tp5_score = 46.0 * tp5_diff\n",
    "    inner = max(tp1_score, tp5_score)\n",
    "    inner = max(0.0, min(inner, 10.0))\n",
    "    pgd_bonus = 0.2 * inner\n",
    "    return pgd_bonus, tp1_score, tp5_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e81f89df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FGSM eps=0.0500: 100%|██████████| 13/13 [00:01<00:00, 10.11it/s]\n",
      "Evaluating (clean)...: 100%|██████████| 13/13 [00:00<00:00, 39.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FGSM eps=0.050] Top1_adv=0.130, Top5_adv=0.750, tp1_diff=0.690, tp5_diff=0.220, eps_emp=0.049, tp1_score=23.100, tp5_score=14.520, est_score=10.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FGSM eps=0.0800: 100%|██████████| 13/13 [00:00<00:00, 13.09it/s]\n",
      "Evaluating (clean)...: 100%|██████████| 13/13 [00:00<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FGSM eps=0.080] Top1_adv=0.050, Top5_adv=0.610, tp1_diff=0.770, tp5_diff=0.360, eps_emp=0.079, tp1_score=25.740, tp5_score=23.760, est_score=10.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FGSM eps=0.1000: 100%|██████████| 13/13 [00:01<00:00, 10.38it/s]\n",
      "Evaluating (clean)...: 100%|██████████| 13/13 [00:00<00:00, 41.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FGSM eps=0.100] Top1_adv=0.040, Top5_adv=0.550, tp1_diff=0.780, tp5_diff=0.420, eps_emp=0.098, tp1_score=26.070, tp5_score=27.720, est_score=10.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FGSM eps=0.1200: 100%|██████████| 13/13 [00:00<00:00, 14.71it/s]\n",
      "Evaluating (clean)...: 100%|██████████| 13/13 [00:00<00:00, 43.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FGSM eps=0.120] Top1_adv=0.020, Top5_adv=0.540, tp1_diff=0.800, tp5_diff=0.430, eps_emp=0.117, tp1_score=26.730, tp5_score=28.380, est_score=10.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FGSM eps=0.1400: 100%|██████████| 13/13 [00:00<00:00, 15.31it/s]\n",
      "Evaluating (clean)...: 100%|██████████| 13/13 [00:00<00:00, 42.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FGSM eps=0.140] Top1_adv=0.030, Top5_adv=0.500, tp1_diff=0.790, tp5_diff=0.470, eps_emp=0.136, tp1_score=26.400, tp5_score=31.020, est_score=10.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FGSM eps=0.1600: 100%|██████████| 13/13 [00:00<00:00, 13.82it/s]\n",
      "Evaluating (clean)...: 100%|██████████| 13/13 [00:00<00:00, 43.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FGSM eps=0.160] Top1_adv=0.030, Top5_adv=0.490, tp1_diff=0.790, tp5_diff=0.480, eps_emp=0.155, tp1_score=26.400, tp5_score=31.680, est_score=10.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FGSM eps=0.1800: 100%|██████████| 13/13 [00:00<00:00, 14.64it/s]\n",
      "Evaluating (clean)...: 100%|██████████| 13/13 [00:00<00:00, 46.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FGSM eps=0.180] Top1_adv=0.040, Top5_adv=0.490, tp1_diff=0.780, tp5_diff=0.480, eps_emp=0.174, tp1_score=26.070, tp5_score=31.680, est_score=10.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FGSM eps=0.2000: 100%|██████████| 13/13 [00:00<00:00, 14.53it/s]\n",
      "Evaluating (clean)...: 100%|██████████| 13/13 [00:00<00:00, 46.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FGSM eps=0.200] Top1_adv=0.050, Top5_adv=0.520, tp1_diff=0.770, tp5_diff=0.450, eps_emp=0.193, tp1_score=25.740, tp5_score=29.700, est_score=10.000\n",
      "\n",
      "[FGSM] Chosen eps: 0.05\n",
      "[FGSM] Chosen eps_emp: 0.04933002591133118\n",
      "[FGSM] Adversarial Top-1 acc: 0.13\n",
      "[FGSM] Adversarial Top-5 acc: 0.75\n",
      "[FGSM] Estimated FGSM score (linear part): 10.0\n",
      "Saved FGSM adversarial images to fgsm.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fgsm_eps_grid = [0.05, 0.08, 0.10, 0.12, 0.14, 0.16, 0.18, 0.20]\n",
    "EPS_THRESHOLD = 0.20  \n",
    "\n",
    "best_fgsm_eps = None\n",
    "best_fgsm_adv_top1 = None\n",
    "best_fgsm_adv_top5 = None\n",
    "best_fgsm_imgs = None\n",
    "best_fgsm_labels = None\n",
    "best_fgsm_score = -1.0\n",
    "best_fgsm_eps_emp = None\n",
    "\n",
    "for eps in fgsm_eps_grid:\n",
    "    adv_imgs_fgsm, adv_lbls_fgsm = build_adv_dataset_fgsm(model, testloader, epsilon=eps)\n",
    "    adv_topk = compute_adv_topk(model, adv_imgs_fgsm, adv_lbls_fgsm, batch_size=BATCH_SIZE)\n",
    "\n",
    "    tp1_diff = abs(orig_topk[1] - adv_topk[1])\n",
    "    tp5_diff = abs(orig_topk[5] - adv_topk[5])\n",
    "    eps_emp  = compute_empirical_eps(input_imgs, adv_imgs_fgsm)\n",
    "\n",
    "    \n",
    "    fgsm_score, tp1_s, tp5_s = estimate_fgsm_score(tp1_diff, tp5_diff, eps_emp)\n",
    "\n",
    "    print(\n",
    "        f\"[FGSM eps={eps:.3f}] \"\n",
    "        f\"Top1_adv={adv_topk[1]:.3f}, Top5_adv={adv_topk[5]:.3f}, \"\n",
    "        f\"tp1_diff={tp1_diff:.3f}, tp5_diff={tp5_diff:.3f}, eps_emp={eps_emp:.3f}, \"\n",
    "        f\"tp1_score={tp1_s:.3f}, tp5_score={tp5_s:.3f}, est_score={fgsm_score:.3f}\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    if eps_emp > EPS_THRESHOLD:\n",
    "        print(f\"  -> Skipping eps={eps:.3f} because eps_emp={eps_emp:.3f} > {EPS_THRESHOLD}\")\n",
    "        continue\n",
    "\n",
    "    \n",
    "    if fgsm_score > best_fgsm_score:\n",
    "        best_fgsm_score = fgsm_score\n",
    "        best_fgsm_eps = eps\n",
    "        best_fgsm_adv_top1 = adv_topk[1]\n",
    "        best_fgsm_adv_top5 = adv_topk[5]\n",
    "        best_fgsm_imgs = adv_imgs_fgsm\n",
    "        best_fgsm_labels = adv_lbls_fgsm\n",
    "        best_fgsm_eps_emp = eps_emp\n",
    "\n",
    "# Fallback: if nothing satisfied eps_emp <= 0.2, pick the smallest eps\n",
    "if best_fgsm_eps is None:\n",
    "    print(\"\\nNo FGSM candidate with eps_emp <= 0.2; falling back to smallest eps in grid.\")\n",
    "    eps = min(fgsm_eps_grid)\n",
    "    adv_imgs_fgsm, adv_lbls_fgsm = build_adv_dataset_fgsm(model, testloader, epsilon=eps)\n",
    "    adv_topk = compute_adv_topk(model, adv_imgs_fgsm, adv_lbls_fgsm, batch_size=BATCH_SIZE)\n",
    "    tp1_diff = abs(orig_topk[1] - adv_topk[1])\n",
    "    tp5_diff = abs(orig_topk[5] - adv_topk[5])\n",
    "    eps_emp = compute_empirical_eps(input_imgs, adv_imgs_fgsm)\n",
    "    fgsm_score, tp1_s, tp5_s = estimate_fgsm_score(tp1_diff, tp5_diff, eps_emp)\n",
    "\n",
    "    best_fgsm_eps = eps\n",
    "    best_fgsm_adv_top1  = adv_topk[1]\n",
    "    best_fgsm_adv_top5  = adv_topk[5]\n",
    "    best_fgsm_imgs = adv_imgs_fgsm\n",
    "    best_fgsm_labels = adv_lbls_fgsm\n",
    "    best_fgsm_eps_emp = eps_emp\n",
    "    best_fgsm_score = fgsm_score\n",
    "\n",
    "print(\"\\n[FGSM] Chosen eps:\", best_fgsm_eps)\n",
    "print(\"[FGSM] Chosen eps_emp:\", best_fgsm_eps_emp)\n",
    "print(\"[FGSM] Adversarial Top-1 acc:\", best_fgsm_adv_top1)\n",
    "print(\"[FGSM] Adversarial Top-5 acc:\", best_fgsm_adv_top5)\n",
    "print(\"[FGSM] Estimated FGSM score (linear part):\", best_fgsm_score)\n",
    "\n",
    "# Save final best FGSM images as List[Tensor] only\n",
    "assert best_fgsm_imgs is not None\n",
    "assert len(best_fgsm_imgs) == NUM_SAMPLES\n",
    "assert best_fgsm_imgs[0].shape == torch.Size([3, 32, 32])\n",
    "\n",
    "torch.save(best_fgsm_imgs, \"fgsm.pt\")\n",
    "print(\"Saved FGSM adversarial images to fgsm.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56747581",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PGD eps=0.0500, iters=40: 100%|██████████| 13/13 [00:35<00:00,  2.71s/it]\n",
      "Evaluating (clean)...: 100%|██████████| 13/13 [00:00<00:00, 45.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PGD eps=0.050] Top1_adv=0.030, Top5_adv=0.580, tp1_diff=0.790, tp5_diff=0.390, eps_emp=0.028, tp1_score=20.540, tp5_score=17.940, est_bonus=2.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PGD eps=0.1000, iters=40: 100%|██████████| 13/13 [00:39<00:00,  3.02s/it]\n",
      "Evaluating (clean)...: 100%|██████████| 13/13 [00:00<00:00, 35.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PGD eps=0.100] Top1_adv=0.000, Top5_adv=0.380, tp1_diff=0.820, tp5_diff=0.590, eps_emp=0.045, tp1_score=21.320, tp5_score=27.140, est_bonus=2.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PGD eps=0.1500, iters=40: 100%|██████████| 13/13 [00:36<00:00,  2.78s/it]\n",
      "Evaluating (clean)...: 100%|██████████| 13/13 [00:00<00:00, 42.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PGD eps=0.150] Top1_adv=0.000, Top5_adv=0.270, tp1_diff=0.820, tp5_diff=0.700, eps_emp=0.056, tp1_score=21.320, tp5_score=32.200, est_bonus=2.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PGD eps=0.2000, iters=40: 100%|██████████| 13/13 [00:39<00:00,  3.02s/it]\n",
      "Evaluating (clean)...: 100%|██████████| 13/13 [00:00<00:00, 32.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PGD eps=0.200] Top1_adv=0.000, Top5_adv=0.220, tp1_diff=0.820, tp5_diff=0.750, eps_emp=0.065, tp1_score=21.320, tp5_score=34.500, est_bonus=2.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PGD eps=0.2500, iters=40: 100%|██████████| 13/13 [00:39<00:00,  3.02s/it]\n",
      "Evaluating (clean)...: 100%|██████████| 13/13 [00:00<00:00, 24.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PGD eps=0.250] Top1_adv=0.000, Top5_adv=0.220, tp1_diff=0.820, tp5_diff=0.750, eps_emp=0.073, tp1_score=21.320, tp5_score=34.500, est_bonus=2.000\n",
      "\n",
      "[PGD] Best eps: 0.2\n",
      "[PGD] Best adversarial Top-1 acc: 0.0\n",
      "[PGD] Best adversarial Top-5 acc: 0.22\n",
      "Saved PGD adversarial images to pgd.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pgd_eps_grid = [0.05, 0.10, 0.15, 0.20, 0.25]\n",
    "PGD_ITERS = 40\n",
    "\n",
    "best_pgd_eps = None\n",
    "best_pgd_adv_top1 = None\n",
    "best_pgd_adv_top5 = None\n",
    "best_pgd_imgs = None\n",
    "best_pgd_labels = None\n",
    "\n",
    "for eps in pgd_eps_grid:\n",
    "    # step size: relatively aggressive but still within eps/iters\n",
    "    alpha = eps / PGD_ITERS\n",
    "\n",
    "    adv_imgs_pgd, adv_lbls_pgd = build_adv_dataset_pgd(\n",
    "        model, testloader, epsilon=eps, alpha=alpha, num_iter=PGD_ITERS\n",
    "    )\n",
    "    adv_topk = compute_adv_topk(model, adv_imgs_pgd, adv_lbls_pgd, batch_size=BATCH_SIZE)\n",
    "\n",
    "    tp1_diff = abs(orig_topk[1] - adv_topk[1])\n",
    "    tp5_diff = abs(orig_topk[5] - adv_topk[5])\n",
    "    eps_emp = compute_empirical_eps(input_imgs, adv_imgs_pgd)\n",
    "\n",
    "    pgd_bonus, tp1_s, tp5_s = estimate_pgd_score(tp1_diff, tp5_diff, eps_emp)\n",
    "\n",
    "    print(\n",
    "        f\"[PGD eps={eps:.3f}] \"\n",
    "        f\"Top1_adv={adv_topk[1]:.3f}, Top5_adv={adv_topk[5]:.3f}, \"\n",
    "        f\"tp1_diff={tp1_diff:.3f}, tp5_diff={tp5_diff:.3f}, eps_emp={eps_emp:.3f}, \"\n",
    "        f\"tp1_score={tp1_s:.3f}, tp5_score={tp5_s:.3f}, est_bonus={pgd_bonus:.3f}\"\n",
    "    )\n",
    "\n",
    "    # Selection rule: minimize adv Top-5 accuracy, then adv Top-1\n",
    "    if best_pgd_eps is None:\n",
    "        choose = True\n",
    "    else:\n",
    "        choose = (\n",
    "            adv_topk[5] < best_pgd_adv_top5 or\n",
    "            (math.isclose(adv_topk[5], best_pgd_adv_top5) and adv_topk[1] < best_pgd_adv_top1)\n",
    "        )\n",
    "\n",
    "    if choose:\n",
    "        best_pgd_eps = eps\n",
    "        best_pgd_adv_top1 = adv_topk[1]\n",
    "        best_pgd_adv_top5 = adv_topk[5]\n",
    "        best_pgd_imgs = adv_imgs_pgd\n",
    "        best_pgd_labels = adv_lbls_pgd\n",
    "\n",
    "print(\"\\n[PGD] Best eps:\", best_pgd_eps)\n",
    "print(\"[PGD] Best adversarial Top-1 acc:\", best_pgd_adv_top1)\n",
    "print(\"[PGD] Best adversarial Top-5 acc:\", best_pgd_adv_top5)\n",
    "\n",
    "assert len(best_pgd_imgs) == NUM_SAMPLES\n",
    "assert best_pgd_imgs[0].shape == torch.Size([3, 32, 32])\n",
    "\n",
    "torch.save(best_pgd_imgs, \"pgd.pt\")\n",
    "print(\"Saved PGD adversarial images to pgd.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
